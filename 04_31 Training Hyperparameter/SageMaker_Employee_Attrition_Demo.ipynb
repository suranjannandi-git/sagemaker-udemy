{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2b7d79",
   "metadata": {},
   "source": [
    "# SageMaker Demo: Employee Attrition Prediction Using Feature Store and XGBoost\n",
    "\n",
    "This notebook demonstrates how to use Amazon SageMaker's Feature Store and XGBoost built-in algorithm to predict employee attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.session import get_execution_role\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for storing data\n",
    "bucket = 'sagemaker-ml3'\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Employee.csv'  # Replace with your actual file path in S3 if needed\n",
    "employee_df = pd.read_csv(file_path)\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275e0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preparation\n",
    "# Convert categorical columns to numeric\n",
    "employee_df['Education'] = employee_df['Education'].astype('category').cat.codes\n",
    "employee_df['City'] = employee_df['City'].astype('category').cat.codes\n",
    "employee_df['Gender'] = employee_df['Gender'].astype('category').cat.codes\n",
    "employee_df['EverBenched'] = employee_df['EverBenched'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Drop rows with NaN values in the target column\n",
    "employee_df.dropna(subset=['LeaveOrNot'])\n",
    "\n",
    "# Convert target column to numeric if needed\n",
    "employee_df['LeaveOrNot'] = employee_df['LeaveOrNot'].astype(int)\n",
    "\n",
    "# Ensure no missing values in feature columns\n",
    "employee_df = employee_df.dropna()\n",
    "\n",
    "# Verify all columns are numeric\n",
    "print(employee_df.dtypes)\n",
    "\n",
    "# Define features and target\n",
    "feature_columns = [\n",
    "    'Education', 'JoiningYear', 'City', 'PaymentTier', 'Age',\n",
    "    'Gender', 'EverBenched', 'ExperienceInCurrentDomain'\n",
    "]\n",
    "target_column = 'LeaveOrNot'\n",
    "\n",
    "employee_df = employee_df[[target_column] + feature_columns]\n",
    "\n",
    "\n",
    "\n",
    "# Display the transformed dataset\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99378560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "# Create a Feature Group\n",
    "feature_group_name = 'employee-feature-group-' + strftime('%Y%m%d%H%M%S', gmtime())\n",
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Define the schema\n",
    "record_identifier_name = 'EmployeeID'  # Unique identifier for records\n",
    "event_time_feature_name = 'EventTime'  # Column representing the time of event\n",
    "\n",
    "# Ensure EventTime is in the correct ISO-8601 format\n",
    "employee_df[event_time_feature_name] = pd.to_datetime('now').strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "employee_df[record_identifier_name] = employee_df.index\n",
    "\n",
    "# Load features to the Feature Store\n",
    "feature_group.load_feature_definitions(data_frame=employee_df)\n",
    "\n",
    "# Enable the Online Store when creating the Feature Group\n",
    "feature_group.create(\n",
    "    s3_uri=f's3://{bucket}/features',\n",
    "    record_identifier_name=record_identifier_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True  # Enable the Online Store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a58c33e-18dc-4d32-8206-837b42c08e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the Feature Group\n",
    "status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "print(f\"Feature Group Status: {status}\")\n",
    "\n",
    "if status == \"Created\":\n",
    "    print(\"Feature Group is Created and ready for use. Proceeding with ingestion...\")\n",
    "    \n",
    "    # Ingest data into the Feature Store\n",
    "    feature_group.ingest(data_frame=employee_df, max_workers=3, wait=True)\n",
    "    print('Data ingested into Feature Store.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Initialize the SageMaker Feature Store runtime client\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "\n",
    "# Define the feature group name and features you want to retrieve\n",
    "feature_names = ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age', 'Gender', 'EverBenched', 'ExperienceInCurrentDomain', 'LeaveOrNot']\n",
    "\n",
    "# Retrieve records and convert to DataFrame\n",
    "records = []\n",
    "for record_id in employee_df.index.astype(str):\n",
    "    response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=feature_group_name,\n",
    "        RecordIdentifierValueAsString=str(record_id),\n",
    "        FeatureNames=feature_names\n",
    "    )\n",
    "    # Check if 'Record' is in the response and add to records list\n",
    "    if 'Record' in response:\n",
    "        record = {feature['FeatureName']: feature['ValueAsString'] for feature in response['Record']}\n",
    "        records.append(record)\n",
    "    else:\n",
    "        print(f\"Record with ID {record_id} not found. Ensure previous step was completed\")\n",
    "\n",
    "# Convert the list of records to a DataFrame\n",
    "retrieved_df = pd.DataFrame(records)\n",
    "\n",
    "# Check if we have any retrieved records\n",
    "if not retrieved_df.empty:\n",
    "    # Split the data into training and test sets\n",
    "    train_df, test_df = train_test_split(retrieved_df, test_size=0.2, random_state=42)\n",
    "    print(\"Training and test data split after retrieval from Feature Store.\")\n",
    "else:\n",
    "    print(\"No records retrieved. Please check the feature group and identifiers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2f17f-7e0e-4a9a-9674-b3c567a64801",
   "metadata": {},
   "source": [
    "## Train the Model Using Local Data with S3 Mode (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573a23c-21c8-45cd-842d-0baf311e00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define your S3 bucket and prefix\n",
    "prefix = 'input-data'\n",
    "\n",
    "# Save the data locally first\n",
    "train_file = 'train.csv'\n",
    "validation_file = 'validation.csv'\n",
    "train_df.to_csv(train_file, index=False)\n",
    "test_df.to_csv(validation_file, index=False)\n",
    "\n",
    "# Upload the data to S3\n",
    "s3.upload_file(train_file, bucket, f'{prefix}/train/{train_file}')\n",
    "s3.upload_file(validation_file, bucket, f'{prefix}/validation/{validation_file}')\n",
    "\n",
    "print(f\"Training data uploaded to s3://{bucket}/{prefix}/train/{train_file}\")\n",
    "print(f\"Validation data uploaded to s3://{bucket}/{prefix}/validation/{validation_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8828f2-f342-4908-b548-513c991127ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "# Set an output path where the trained model will be saved\n",
    "prefix = 'demo-built-in-algorithm'\n",
    "output_path = f's3://{bucket}/{prefix}/output'\n",
    "\n",
    "# Retrieve the XGBoost image URI\n",
    "region = boto3.Session().region_name  # Automatically get the region\n",
    "xgboost_container = image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "# Construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge', \n",
    "                                          volume_size=5,  # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "# Define the data type and paths to the training and validation datasets\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(f\"s3://{bucket}/input-data/train/\", content_type=content_type)\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/input-data/validation/\", content_type=content_type)\n",
    "\n",
    "# Execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
