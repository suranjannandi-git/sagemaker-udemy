{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b2b7d79",
   "metadata": {},
   "source": [
    "# SageMaker Demo: Employee Attrition Prediction Using Feature Store and XGBoost\n",
    "\n",
    "This notebook demonstrates how to use Amazon SageMaker's Feature Store and XGBoost built-in algorithm to predict employee attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07bc85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>LeaveOrNot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2017</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pune</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelors</td>\n",
       "      <td>2014</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2016</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masters</td>\n",
       "      <td>2017</td>\n",
       "      <td>Pune</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n",
       "0  Bachelors         2017  Bangalore            3   34    Male          No   \n",
       "1  Bachelors         2013       Pune            1   28  Female          No   \n",
       "2  Bachelors         2014  New Delhi            3   38  Female          No   \n",
       "3    Masters         2016  Bangalore            3   27    Male          No   \n",
       "4    Masters         2017       Pune            3   24    Male         Yes   \n",
       "\n",
       "   ExperienceInCurrentDomain  LeaveOrNot  \n",
       "0                          0           0  \n",
       "1                          3           1  \n",
       "2                          2           0  \n",
       "3                          5           1  \n",
       "4                          2           1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Setup\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for storing data\n",
    "bucket = 'sagemaker-ml-28573'\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Employee.csv'  # Replace with your actual file path in S3 if needed\n",
    "employee_df = pd.read_csv(file_path)\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275e0021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LeaveOrNot</th>\n",
       "      <th>Education</th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>City</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>EverBenched</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LeaveOrNot  Education  JoiningYear  City  PaymentTier  Age  Gender  \\\n",
       "0           0          0         2017     0            3   34       1   \n",
       "1           1          0         2013     2            1   28       0   \n",
       "2           0          0         2014     1            3   38       0   \n",
       "3           1          1         2016     0            3   27       1   \n",
       "4           1          1         2017     2            3   24       1   \n",
       "\n",
       "   EverBenched  ExperienceInCurrentDomain  \n",
       "0            0                          0  \n",
       "1            0                          3  \n",
       "2            0                          2  \n",
       "3            0                          5  \n",
       "4            1                          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Data Preparation\n",
    "# Convert categorical columns to numeric\n",
    "employee_df['Education'] = employee_df['Education'].astype('category').cat.codes\n",
    "employee_df['City'] = employee_df['City'].astype('category').cat.codes\n",
    "employee_df['Gender'] = employee_df['Gender'].astype('category').cat.codes\n",
    "employee_df['EverBenched'] = employee_df['EverBenched'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Drop rows with NaN values in the target column\n",
    "employee_df.dropna(subset=['LeaveOrNot'])\n",
    "\n",
    "# Convert target column to numeric if needed\n",
    "employee_df['LeaveOrNot'] = employee_df['LeaveOrNot'].astype(int)\n",
    "\n",
    "# Ensure no missing values in feature columns\n",
    "employee_df = employee_df.dropna()\n",
    "\n",
    "# Verify all columns are numeric\n",
    "print(employee_df.dtypes)\n",
    "\n",
    "# Define features and target\n",
    "feature_columns = [\n",
    "    'Education', 'JoiningYear', 'City', 'PaymentTier', 'Age',\n",
    "    'Gender', 'EverBenched', 'ExperienceInCurrentDomain'\n",
    "]\n",
    "target_column = 'LeaveOrNot'\n",
    "\n",
    "employee_df = employee_df[[target_column] + feature_columns]\n",
    "\n",
    "\n",
    "\n",
    "# Display the transformed dataset\n",
    "employee_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99378560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FeatureGroupArn': 'arn:aws:sagemaker:us-east-1:448049810900:feature-group/employee-feature-group-20240829131409',\n",
       " 'ResponseMetadata': {'RequestId': 'eab083de-aeee-4f25-adf5-9b26e0f5d24d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'eab083de-aeee-4f25-adf5-9b26e0f5d24d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '114',\n",
       "   'date': 'Thu, 29 Aug 2024 13:14:09 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "# Create a Feature Group\n",
    "feature_group_name = 'employee-feature-group-' + strftime('%Y%m%d%H%M%S', gmtime())\n",
    "feature_group = FeatureGroup(name=feature_group_name, sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Define the schema\n",
    "record_identifier_name = 'EmployeeID'  # Unique identifier for records\n",
    "event_time_feature_name = 'EventTime'  # Column representing the time of event\n",
    "\n",
    "# Ensure EventTime is in the correct ISO-8601 format\n",
    "employee_df[event_time_feature_name] = pd.to_datetime('now').strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "employee_df[record_identifier_name] = employee_df.index\n",
    "\n",
    "# Load features to the Feature Store\n",
    "feature_group.load_feature_definitions(data_frame=employee_df)\n",
    "\n",
    "# Enable the Online Store when creating the Feature Group\n",
    "feature_group.create(\n",
    "    s3_uri='s3://sagemaker-ml-28573/features',\n",
    "    record_identifier_name=record_identifier_name,\n",
    "    event_time_feature_name=event_time_feature_name,\n",
    "    role_arn=role,\n",
    "    enable_online_store=True  # Enable the Online Store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a58c33e-18dc-4d32-8206-837b42c08e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group Status: Created\n",
      "Feature Group is Created and ready for use. Proceeding with ingestion...\n",
      "Data ingested into Feature Store.\n"
     ]
    }
   ],
   "source": [
    "# Check the status of the Feature Group\n",
    "status = feature_group.describe().get(\"FeatureGroupStatus\")\n",
    "print(f\"Feature Group Status: {status}\")\n",
    "\n",
    "if status == \"Created\":\n",
    "    print(\"Feature Group is Created and ready for use. Proceeding with ingestion...\")\n",
    "    \n",
    "    # Ingest data into the Feature Store\n",
    "    feature_group.ingest(data_frame=employee_df, max_workers=3, wait=True)\n",
    "    print('Data ingested into Feature Store.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "039b5877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and test data split after retrieval from Feature Store.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Initialize the SageMaker Feature Store runtime client\n",
    "featurestore_runtime = boto3.client('sagemaker-featurestore-runtime')\n",
    "\n",
    "# Define the feature group name and features you want to retrieve\n",
    "feature_names = ['Education', 'JoiningYear', 'City', 'PaymentTier', 'Age', 'Gender', 'EverBenched', 'ExperienceInCurrentDomain', 'LeaveOrNot']\n",
    "\n",
    "# Retrieve records and convert to DataFrame\n",
    "records = []\n",
    "for record_id in employee_df.index.astype(str):\n",
    "    response = featurestore_runtime.get_record(\n",
    "        FeatureGroupName=feature_group_name,\n",
    "        RecordIdentifierValueAsString=str(record_id),\n",
    "        FeatureNames=feature_names\n",
    "    )\n",
    "    # Check if 'Record' is in the response and add to records list\n",
    "    if 'Record' in response:\n",
    "        record = {feature['FeatureName']: feature['ValueAsString'] for feature in response['Record']}\n",
    "        records.append(record)\n",
    "    else:\n",
    "        print(f\"Record with ID {record_id} not found.\")\n",
    "\n",
    "# Convert the list of records to a DataFrame\n",
    "retrieved_df = pd.DataFrame(records)\n",
    "\n",
    "# Check if we have any retrieved records\n",
    "if not retrieved_df.empty:\n",
    "    # Split the data into training and test sets\n",
    "    train_df, test_df = train_test_split(retrieved_df, test_size=0.2, random_state=42)\n",
    "    print(\"Training and test data split after retrieval from Feature Store.\")\n",
    "else:\n",
    "    print(\"No records retrieved. Please check the feature group and identifiers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc2f17f-7e0e-4a9a-9674-b3c567a64801",
   "metadata": {},
   "source": [
    "## Train the Model Using Local Data with S3 Mode (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8573a23c-21c8-45cd-842d-0baf311e00c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data uploaded to s3://sagemaker-ml-28573/input-data/train/train.csv\n",
      "Validation data uploaded to s3://sagemaker-ml-28573/input-data/validation/validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define your S3 bucket and prefix\n",
    "bucket = 'sagemaker-ml-28573'\n",
    "prefix = 'input-data'\n",
    "\n",
    "# Save the data locally first\n",
    "train_file = 'train.csv'\n",
    "validation_file = 'validation.csv'\n",
    "train_df.to_csv(train_file, index=False)\n",
    "test_df.to_csv(validation_file, index=False)\n",
    "\n",
    "# Upload the data to S3\n",
    "s3.upload_file(train_file, bucket, f'{prefix}/train/{train_file}')\n",
    "s3.upload_file(validation_file, bucket, f'{prefix}/validation/{validation_file}')\n",
    "\n",
    "print(f\"Training data uploaded to s3://{bucket}/{prefix}/train/{train_file}\")\n",
    "print(f\"Validation data uploaded to s3://{bucket}/{prefix}/validation/{validation_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb8828f2-f342-4908-b548-513c991127ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2024-08-29-13-30-18-037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-29 13:30:20 Starting - Starting the training job...\n",
      "2024-08-29 13:30:35 Starting - Preparing the instances for training...\n",
      "2024-08-29 13:31:02 Downloading - Downloading input data...\n",
      "2024-08-29 13:31:27 Downloading - Downloading the training image...\n",
      "2024-08-29 13:32:18 Training - Training image download completed. Training in progress...\u001b[34m[2024-08-29 13:32:29.133 ip-10-0-204-133.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.156 ip-10-0-204-133.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] File path /opt/ml/input/data/train of input files\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Making smlinks from folder /opt/ml/input/data/train to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] creating symlink between Path /opt/ml/input/data/train/train.csv and destination /tmp/sagemaker_xgboost_input_data/train.csv6998196806997737259\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] File path /opt/ml/input/data/validation of input files\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Making smlinks from folder /opt/ml/input/data/validation to folder /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] creating symlink between Path /opt/ml/input/data/validation/validation.csv and destination /tmp/sagemaker_xgboost_input_data/validation.csv-3076688514761617586\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] files path: /tmp/sagemaker_xgboost_input_data\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Train matrix has 3723 rows and 8 columns\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Validation matrix has 932 rows\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.612 ip-10-0-204-133.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.612 ip-10-0-204-133.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.613 ip-10-0-204-133.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.613 ip-10-0-204-133.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2024-08-29:13:32:29:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:0.45609#011validation-rmse:0.45206\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.620 ip-10-0-204-133.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2024-08-29 13:32:29.624 ip-10-0-204-133.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:0.42381#011validation-rmse:0.41663\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:0.40621#011validation-rmse:0.39714\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:0.38864#011validation-rmse:0.37689\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:0.37875#011validation-rmse:0.36538\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:0.37016#011validation-rmse:0.35544\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:0.36835#011validation-rmse:0.35322\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:0.36793#011validation-rmse:0.35275\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:0.36490#011validation-rmse:0.34936\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:0.36471#011validation-rmse:0.34912\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:0.36332#011validation-rmse:0.34746\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:0.36232#011validation-rmse:0.34668\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:0.36017#011validation-rmse:0.34423\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:0.36015#011validation-rmse:0.34421\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:0.35805#011validation-rmse:0.34199\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:0.35804#011validation-rmse:0.34197\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:0.35566#011validation-rmse:0.33814\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:0.35405#011validation-rmse:0.33631\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:0.35405#011validation-rmse:0.33631\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:0.35406#011validation-rmse:0.33632\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:0.35406#011validation-rmse:0.33632\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:0.35406#011validation-rmse:0.33631\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:0.35406#011validation-rmse:0.33631\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:0.35405#011validation-rmse:0.33630\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:0.35406#011validation-rmse:0.33632\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:0.35406#011validation-rmse:0.33632\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:0.35406#011validation-rmse:0.33633\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:0.35406#011validation-rmse:0.33632\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:0.35304#011validation-rmse:0.33550\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:0.35304#011validation-rmse:0.33549\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:0.35304#011validation-rmse:0.33548\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:0.35304#011validation-rmse:0.33548\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:0.35304#011validation-rmse:0.33547\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:0.35304#011validation-rmse:0.33547\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:0.35304#011validation-rmse:0.33548\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:0.35154#011validation-rmse:0.33381\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:0.35017#011validation-rmse:0.33263\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:0.35017#011validation-rmse:0.33263\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:0.35017#011validation-rmse:0.33262\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:0.35017#011validation-rmse:0.33261\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:0.35017#011validation-rmse:0.33262\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:0.35017#011validation-rmse:0.33261\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:0.35017#011validation-rmse:0.33261\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:0.35016#011validation-rmse:0.33261\u001b[0m\n",
      "\n",
      "2024-08-29 13:32:47 Uploading - Uploading generated training model\n",
      "2024-08-29 13:32:47 Completed - Training job completed\n",
      "Training seconds: 104\n",
      "Billable seconds: 104\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# Initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"50\"}\n",
    "\n",
    "# Set an output path where the trained model will be saved\n",
    "bucket = 'sagemaker-ml-28573'\n",
    "prefix = 'demo-built-in-algorithm'\n",
    "output_path = f's3://{bucket}/{prefix}/output'\n",
    "\n",
    "# Retrieve the XGBoost image URI\n",
    "region = boto3.Session().region_name  # Automatically get the region\n",
    "xgboost_container = image_uris.retrieve(\"xgboost\", region, \"1.7-1\")\n",
    "\n",
    "# Construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge', \n",
    "                                          volume_size=5,  # 5 GB \n",
    "                                          output_path=output_path)\n",
    "\n",
    "# Define the data type and paths to the training and validation datasets\n",
    "content_type = \"csv\"\n",
    "train_input = TrainingInput(f\"s3://{bucket}/input-data/train/\", content_type=content_type)\n",
    "validation_input = TrainingInput(f\"s3://{bucket}/input-data/validation/\", content_type=content_type)\n",
    "\n",
    "# Execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
